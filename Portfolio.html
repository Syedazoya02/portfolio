<!DOCTYPE html>
<html>
<head>
<title>Font Awesome Icons</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src='https://kit.fontawesome.com/a076d05399.js' crossorigin='anonymous'></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
  body {
    background-color: black;
    font-family: sans-serif;
    color: wheat;
    margin: 40px;
    line-height: 1.6;
  }

  h1, h2 {
    margin-bottom: 20px;
  }

  ol {
    list-style-type: none;
    padding: 0;
  }

  li {
    margin-bottom: 20px;
  }

  i {
    margin-right: 10px;
  }

  p {
    font-size: 16px;
  }
</style>
</head>
<body>
<h1><i><b>Projects</b></i></h1>
<ol>
  <li>
    <i class="fa fa-fire" style="font-size: 24px; color: rgb(148, 7, 7)"></i>Fire Alert System
    <p>A model that detects the fire and controls the fire by automatically sprinkling water. Embedded C programming language was used in this project. We Implemented embedded C programming on 8051 microcontroller. Configuration of all components on 8051 development board.</p>
  </li>
  <li>
    <i class="fa fa-taxi" style="font-size: 24px; color: rgb(148, 7, 7)"></i>Autonomous Delivery Bot (Collision Avoidance)
    <p>The goal of this project is to have the robot identify barriers and, if they are identified, they take proper diversion. The techniques used in project include open cv and collision avoidance. The robot uses Jetson nano, pytorch, TorchVision nad jupyter Notebook. This robot can analyse sensor data in real-time and react dynamically to the environment because of computing capacity of jetson nano.</p>
  </li>
</ol>
<h2>Publication-</h2>
<p>
  <i class="fa fa-hand-pointer-o" style="font-size: 24px; color: rgb(148, 7, 7)"></i>"Hand Gesture Detection using Transfer Learning with Deep Neural Networks"
</p>
<p>Large segments of the population value sign language as one of the many languages used for communication. Each sign in each sign language differs in terms of hand shape, motion profile, and positioning of the hand. These differences will have a substantial influence on the accuracy and reliability of the identification process. Therefore, one of the key techniques for detecting gestures is sign language identification utilizing deep learning. In this paper, we have considered four major algorithms of Image classification EfficientNet- B0, GoogleNet, ResNext 50 32x4d and MobileNet-V2 which were tested on GPU system. To determine the optimum model that uses the fewest GPU cores, many factors have been considered, including training time, training accuracy, total loss and inference. GoogleNet performance is better as compared to other models.</p>
</body>
</html>
